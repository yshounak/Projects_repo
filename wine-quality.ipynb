{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Deep Learning Libraries\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# MLflow for Experiment Tracking\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "from hyperopt import (\n",
    "    STATUS_OK,\n",
    "    Trials,\n",
    "    fmin,\n",
    "    hp,\n",
    "    tpe\n",
    ")\n",
    "\n",
    "# Machine Learning Metrics and Preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Wine Quality Dataset\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\", \n",
    "    sep=\";\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting Strategy\n",
    "\n",
    "## Initial Train-Test Split\n",
    "train, test = train_test_split(\n",
    "    data, \n",
    "    test_size=0.25,  # 25% for testing\n",
    "    random_state=42  # Reproducibility\n",
    ")\n",
    "\n",
    "## Separate Features and Target Variable for Training Set\n",
    "train_x = train.drop(['quality'], axis=1).values\n",
    "train_y = train[['quality']].values.ravel()\n",
    "\n",
    "## Separate Features and Target Variable for Test Set\n",
    "test_x = test.drop(['quality'], axis=1).values\n",
    "test_y = test[['quality']].values.ravel()\n",
    "\n",
    "## Further Split Training Data into Train and Validation Sets\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(\n",
    "    train_x, \n",
    "    train_y, \n",
    "    test_size=0.20,  # 20% of training data for validation\n",
    "    random_state=42  # Reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params, epochs, train_x, train_y, valid_x, valid_y, test_x, test_y):\n",
    "    \"\"\"\n",
    "    Train an Artificial Neural Network with MLflow tracking\n",
    "    \n",
    "    Args:\n",
    "        params (dict): Hyperparameters for model training\n",
    "        epochs (int): Number of training epochs\n",
    "        train_x, train_y: Training data\n",
    "        valid_x, valid_y: Validation data\n",
    "        test_x, test_y: Test data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Model evaluation results\n",
    "    \"\"\"\n",
    "    ## Data Normalization\n",
    "    mean = np.mean(train_x, axis=0)\n",
    "    var = np.var(train_x, axis=0)\n",
    "\n",
    "    ## Model Architecture\n",
    "    model = keras.Sequential([\n",
    "        keras.Input([train_x.shape[1]]),\n",
    "        keras.layers.Normalization(mean=mean, variance=var),\n",
    "        keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    ## Model Compilation\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate=params[\"lr\"],\n",
    "            decay=params.get(\"decay\", 1e-6)\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    ## Early Stopping and Checkpoint\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10, \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        'best_model.h5', \n",
    "        save_best_only=True\n",
    "    )\n",
    "\n",
    "    ## MLflow Tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Training with callbacks\n",
    "        history = model.fit(\n",
    "            train_x, train_y,\n",
    "            validation_data=(valid_x, valid_y),\n",
    "            epochs=epochs,\n",
    "            batch_size=64,\n",
    "            callbacks=[early_stopping, model_checkpoint],\n",
    "            verbose=0  # Suppress training logs\n",
    "        )\n",
    "\n",
    "    ## Model Evaluation\n",
    "    eval_result = model.evaluate(valid_x, valid_y, batch_size=64)\n",
    "    eval_rmse = eval_result[1]\n",
    "\n",
    "    ## MLflow Logging\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"eval_rmse\", eval_rmse)\n",
    "        mlflow.log_metric(\"train_loss\", history.history['loss'][-1])\n",
    "        mlflow.log_metric(\"val_loss\", history.history['val_loss'][-1])\n",
    "\n",
    "        # Log model\n",
    "        mlflow.tensorflow.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "    return {\n",
    "        \"loss\": eval_rmse, \n",
    "        \"status\": STATUS_OK, \n",
    "        \"model\": model\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Hyperopt\n",
    "    \n",
    "    Args:\n",
    "        params (dict): Hyperparameters to be tuned\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results from model training\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # MLflow will track the parameters and results for each run\n",
    "        result = train_model(\n",
    "            params,\n",
    "            epochs=3,\n",
    "            train_x=train_x,\n",
    "            train_y=train_y,\n",
    "            valid_x=valid_x,  # Corrected from valid_y\n",
    "            valid_y=valid_y,\n",
    "            test_x=test_x,\n",
    "            test_y=test_y\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in objective function: {e}\")\n",
    "        return {\n",
    "            'loss': float('inf'),\n",
    "            'status': STATUS_FAIL\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Search Space Configuration\n",
    "space = {\n",
    "    # Learning Rate Configuration\n",
    "    \"lr\": hp.loguniform(\n",
    "        \"lr\", \n",
    "        np.log(1e-5),  # Minimum learning rate\n",
    "        np.log(1e-1)   # Maximum learning rate\n",
    "    ),\n",
    "    \n",
    "    # Momentum Configuration\n",
    "    \"momentum\": hp.uniform(\n",
    "        \"momentum\", \n",
    "        0.0,  # Minimum momentum\n",
    "        1.0   # Maximum momentum\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/20 15:59:18 INFO mlflow.tracking.fluent: Experiment with name 'WineQuality' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6732 - root_mean_squared_error: 0.7845\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8229 - root_mean_squared_error: 0.8739 \n",
      "\n",
      " 25%|██▌       | 1/4 [00:05<00:16,  5.48s/trial, best loss: 0.8912836313247681]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 35.0877 - root_mean_squared_error: 5.9183\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34.4604 - root_mean_squared_error: 5.8650 \n",
      "\n",
      " 50%|█████     | 2/4 [00:10<00:10,  5.11s/trial, best loss: 0.8912836313247681]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6685 - root_mean_squared_error: 1.2652\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1436 - root_mean_squared_error: 1.4392 \n",
      "\n",
      " 75%|███████▌  | 3/4 [00:15<00:05,  5.13s/trial, best loss: 0.8912836313247681]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6849 - root_mean_squared_error: 0.7837\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7055 - root_mean_squared_error: 0.7966 \n",
      "\n",
      "100%|██████████| 4/4 [00:20<00:00,  5.03s/trial, best loss: 0.8174808025360107]\n",
      "Best Parameters: {'lr': np.float64(0.037981348649503636), 'momentum': np.float64(0.44598871471430435)}\n",
      "Best Evaluation RMSE: 0.8174808025360107\n"
     ]
    }
   ],
   "source": [
    "# MLflow Experiment Tracking and Hyperparameter Optimization\n",
    "\n",
    "try:\n",
    "    # Set MLflow Experiment\n",
    "    mlflow.set_experiment(\"WineQuality\")\n",
    "\n",
    "    # Start MLflow Run\n",
    "    with mlflow.start_run():\n",
    "        # Hyperparameter Search Configuration\n",
    "        trials = Trials()\n",
    "        best = fmin(\n",
    "            fn=objective,           # Objective function\n",
    "            space=space,            # Hyperparameter search space\n",
    "            algo=tpe.suggest,       # Tree of Parzen Estimators algorithm\n",
    "            max_evals=4,            # Maximum number of evaluations\n",
    "            trials=trials\n",
    "        )\n",
    "\n",
    "        # Error Handling and Best Run Selection\n",
    "        try:\n",
    "            # Sort trials by loss and select best run\n",
    "            best_run = min(trials.results, key=lambda x: x['loss'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error selecting best run: {e}\")\n",
    "            best_run = None\n",
    "\n",
    "        # Logging Best Parameters and Results\n",
    "        if best_run:\n",
    "            mlflow.log_params(best)\n",
    "            mlflow.log_metric(\"eval_rmse\", best_run['loss'])\n",
    "            \n",
    "            # Log the best model\n",
    "            if 'model' in best_run:\n",
    "                mlflow.tensorflow.log_model(\n",
    "                    best_run['model'], \n",
    "                    \"model\", \n",
    "                    signature=signature\n",
    "                )\n",
    "\n",
    "            # Print Results\n",
    "            print(f\"Best Parameters: {best}\")\n",
    "            print(f\"Best Evaluation RMSE: {best_run['loss']}\")\n",
    "        else:\n",
    "            print(\"No valid runs found during hyperparameter optimization\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in MLflow experiment tracking: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating model with best parameters for Deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shounak/Documents/MLOps/MLFlow/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 4507.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/shounak/Documents/MLOps/MLFlow/venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.749973 ],\n",
       "       [6.7099586],\n",
       "       [6.4850783],\n",
       "       ...,\n",
       "       [6.34512  ],\n",
       "       [6.921927 ],\n",
       "       [5.852235 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inferencing\n",
    "\n",
    "from mlflow.models import validate_serving_input\n",
    "\n",
    "model_uri = 'runs:/e524fcf150544e9a9677772f0cacf7af/model'\n",
    "\n",
    "# The logged model does not contain an input_example.\n",
    "# Manually generate a serving payload to verify your model prior to deployment.\n",
    "from mlflow.models import convert_input_example_to_serving_input\n",
    "\n",
    "# Define INPUT_EXAMPLE via assignment with your own input example to the model\n",
    "# A valid input example is a data instance suitable for pyfunc prediction\n",
    "serving_payload = convert_input_example_to_serving_input(test_x)\n",
    "\n",
    "# Validate the serving payload works on the model\n",
    "validate_serving_input(model_uri, serving_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shounak/Documents/MLOps/MLFlow/venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.749973 ],\n",
       "       [6.7099586],\n",
       "       [6.4850783],\n",
       "       ...,\n",
       "       [6.34512  ],\n",
       "       [6.921927 ],\n",
       "       [5.852235 ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model as PyFuncModel.\n",
    "model_uri = 'runs:/e524fcf150544e9a9677772f0cacf7af/model'\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Predict on a Pandas DataFrame\n",
    "loaded_model.predict(pd.DataFrame(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Register the model through code \n",
    "#mlflow.register_model(model_uri, \"wine-quality\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
